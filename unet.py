# -*- coding: utf-8 -*-
"""Copy of UNET.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FNqzC6gyvyLH3GqfiqMUYGIwPSFLo73M

# U-net model

# package
"""

import cv2
import numpy as np
import tensorflow as tf
from tensorflow import keras
#from tensorflow.keras import layers
from keras import layers
import keras.backend as K


"""#losses and metrics"""

def accuracy(y_true,y_pred):
  accuracy = K.sum(tf.cast((y_true==y_pred),tf.float32))/tf.cast(K.prod(K.shape(y_true)),tf.float32)
  return accuracy

def IoU(y_true,y_pred):
  true_pos = K.sum(K.round(K.clip(y_true*y_pred,0,1)))
  #print("True pos: ", true_pos)
  total_pos = K.sum(K.round(K.clip(y_pred,0,1)))
  #print("total pos: ", total_pos)
  ground_pos = K.sum(y_true)
  #print("ground truth positive:",ground_pos)
  false_pos = total_pos - true_pos
  #print("false pos", false_pos)
  false_neg = ground_pos - true_pos
  #print("false neg", false_neg)
  IoU = (true_pos)/(true_pos + false_pos + false_neg + K.epsilon())
  return IoU

def precision(y_true,y_pred):
  true_pos = K.sum(K.round(K.clip(y_true*y_pred,0,1)))
  total_pos = K.sum(K.round(K.clip(y_pred,0,1)))
  precision = true_pos/(total_pos + K.epsilon())
  return precision

def recall(y_true,y_pred):
  true_pos = K.sum(K.round(K.clip(tf.cast(y_true,tf.float32)*y_pred,0,1)))
  ground_pos = K.sum(y_true)
  recall = true_pos/(ground_pos + K.epsilon())
  return recall

def F1_score(y_true,y_pred):
  prec = precision(y_true,y_pred)
  rec = recall(y_true,y_pred)
  F1_score = (2*prec*rec)/(prec+rec + K.epsilon())
  return F1_score

def class_weight(labels):
  building_ratio = sum(sum(sum(labels)))/(labels.shape[0]*256*256)
  return building_ratio


def dice_coef(y_true, y_pred):
  smooth = 1
  y_true_f = K.flatten(y_true)
  y_pred_f = K.flatten(y_pred)
  intersection = K.sum(tf.cast(y_true_f,tf.float32)* y_pred_f)
  return (2. * intersection + smooth) / (K.sum(tf.cast(y_true_f,tf.float32)) + K.sum(y_pred_f) + smooth)
    
    
def dice_coef_loss(y_true, y_pred):
  return 1 - dice_coef(y_true, y_pred)

def compound_loss(y_true,y_pred):
  return 0.9*dice_coef_loss(y_true,y_pred)+ 0.1*weighted_bce(y_true, y_pred)

def weighted_bce(y_true,y_pred):
  num_pred = K.sum(K.cast(y_pred < 0.5, y_true.dtype)) + K.sum(y_true)    
  zero_weight =  K.sum(y_true)/ num_pred +  K.epsilon() 
  one_weight = K.sum(K.cast(y_pred < 0.5, y_true.dtype)) / num_pred +  K.epsilon()
  weights =  (1.0 - y_true) * zero_weight +  y_true * one_weight 
  bin_crossentropy = K.binary_crossentropy(y_true, y_pred)
  weighted_bin_crossentropy = weights * bin_crossentropy 
  return K.mean(weighted_bin_crossentropy)


"""the double_conv_blolk used for  encoder and the bottleneck (bottom block)

"""

def double_conv_block(x, n_filters):

    # Conv2D then ReLU activation
    x = layers.Conv2D(n_filters, 3, padding = "same", activation = "relu", kernel_initializer = "he_normal")(x)
    # Conv2D then ReLU activation
    x = layers.Conv2D(n_filters, 3, padding = "same", activation = "relu", kernel_initializer = "he_normal")(x)

    return x

def downsample_block(x, n_filters):
    f = double_conv_block(x, n_filters)
    p = layers.MaxPool2D(2)(f)
    p = layers.Dropout(0.3)(p)

    return f, p

""" encoder
 
"""

def upsample_block(x, conv_features, n_filters):
    # upsample
    x = layers.Conv2DTranspose(n_filters, 3, 2, padding="same")(x)
    # concatenate 
    x = layers.concatenate([x, conv_features])
    # dropout
    x = layers.Dropout(0.3)(x)
    # Conv2D twice with ReLU activation
    x = double_conv_block(x, n_filters)

    return x

"""https://colab.research.google.com/github/margaretmz/image-segmentation/blob/main/unet_pet_segmentation.ipynb#scrollTo=CpBaxoS4LBuo


paper:
https://arxiv.org/abs/1505.04597

# U_net model
"""

def build_unet_model():
    # inputs


    inputs = layers.Input(shape=(256,256,1))

    # encoder: contracting path - downsample
    # 1 - downsample
    f1, p1 = downsample_block(inputs, 64)
    # 2 - downsample
    f2, p2 = downsample_block(p1, 128)
    # 3 - downsample
    f3, p3 = downsample_block(p2, 256)
    # 4 - downsample
    f4, p4 = downsample_block(p3, 512)

    # 5 - bottleneck
    bottleneck = double_conv_block(p4, 1024)

    # decoder: expanding path - upsample
    # 6 - upsample
    u6 = upsample_block(bottleneck, f4, 512)
    # 7 - upsample
    u7 = upsample_block(u6, f3, 256)
    # 8 - upsample
    u8 = upsample_block(u7, f2, 128)
    # 9 - upsample
    u9 = upsample_block(u8, f1, 64)

    # outputs
    outputs = layers.Conv2D(1, 1, padding="same", activation = "sigmoid")(u9)

    # unet model with Keras Functional API
    unet_model = tf.keras.Model(inputs, outputs, name="U-Net")

    return unet_model

UNET=build_unet_model()
UNET.compile(tf.keras.optimizers.Adam(learning_rate=1e-4),
             loss=compound_loss,
             metrics =[keras.metrics.BinaryIoU(target_class_ids=[1]),precision,recall,F1_score])

UNET.summary()

img_train = np.load("processed_data/img_train.npy")/255.0
img_test = np.load("processed_data/img_test.npy")/255.0
label_train = np.load("processed_data/label_train.npy").astype(np.float32)
label_test = np.load("processed_data/label_test.npy").astype(np.float32)


checkpoint_filepath = '/tmp/checkpoint'
model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
    filepath=checkpoint_filepath,
    save_weights_only=True,
    monitor='val_binary_io_u',
    mode='max',
    save_best_only=True)


history = UNET.fit(img_train,label_train, batch_size=128, epochs= 15,validation_data=(img_test,label_test),callbacks=[model_checkpoint_callback])


UNET.load_weights(checkpoint_filepath)

UNET.save('unet_model')
np.save('unet_training_history.npy',history.history)